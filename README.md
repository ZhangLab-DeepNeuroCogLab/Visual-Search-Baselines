# Visual-Search-Baselines

This repository contains the baseline models used in the [TCT](https://arxiv.org/pdf/2211.13470) paper for visual search analysis and benchmarking.  
The baselines span multiple paradigms, including contextual reasoning, human scanpath modeling, and computational saliency.

## ðŸ“„ Baselines

### 1. CRTNet (Context-aware Recognition Transformer Network )
> **Reference**:  
> Bomatter, P., Zhang, M., Karev, D., Madan, S., Tseng, C., & Kreiman, G. (2021).  
> *When pigs fly: Contextual reasoning in synthetic and natural scenes.*  
> In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 255â€“264).  
> [Paper Link](https://openaccess.thecvf.com/content/ICCV2021/papers/Bomatter_When_Pigs_Fly_Contextual_Reasoning_in_Synthetic_and_Natural_Scenes_ICCV_2021_paper.pdf)

### 2. DeepGaze III
> **Reference**:  
> KÃ¼mmerer, M., Bethge, M., & Wallis, T. S. (2022).  
> *DeepGaze III: Modeling free-viewing human scanpaths with deep learning.*  
> Journal of Vision, 22(5), 7â€“7.  
> [Project Page](https://deepgaze.bethgelab.org/)

### 3. Detectron2
> **Reference**:  
> Facebook AI Research (FAIR).  
> [GitHub Repository](https://github.com/facebookresearch/detectron2)  
> Detectron2 is a high-performance library for object detection and segmentation.

### 4. GBVS (Graph-Based Visual Saliency)
> **Reference**:  
> Harel, J., Koch, C., & Perona, P. (2006).  
> *Graph-based visual saliency.*  
> Advances in Neural Information Processing Systems, 19.  
> [Project Page](http://www.vision.caltech.edu/~harel/share/gbvs.php)


---

**Note**: This repository only organizes and documents the baseline methods; their original implementations belong to their respective authors.
